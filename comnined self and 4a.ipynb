{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a9251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/02 11:10:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/02 11:10:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/11/02 11:10:38 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "#Note that you only need execue this block once per session. Once you have the link to spark (sc has a value) \n",
    "#it causes and error if you repeat this\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession\\\n",
    ".builder\\\n",
    ".appName(\"Python Spark SQL\")\\\n",
    ".config(\"spark.some.config.option\", \"some-value\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4321abe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://259a0375daa1:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Python Spark SQL</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Python Spark SQL>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check we have a spark context: Should show the spark version and app name\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a0c1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 notebookuser notebookuser 30774793 Oct 28 14:58 DigitalBreathTestData2013.csv\n",
      "/home/notebookuser/working/data\n"
     ]
    }
   ],
   "source": [
    "!ls -l *.csv\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e4eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is Crown Copyright published under Open Government Licence v3.0, \n",
    "#https://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/\n",
    "\n",
    "#***Tears before bedtime!!!*** --- Triple check your file is REALLY on the pathname ***\n",
    "#lines = sc.textFile(\"file:///home/student/izje1/DigitalBreathTestData2013.txt\")\n",
    "lines = sc.textFile(\"DigitalBreathTestData2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f78ea06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "header = lines.first() #extract header\n",
    "justdata = lines.filter(lambda row: row != header)   #filter out header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec67926",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First split the file into columns, and just use the first column ('Reason') as the key\n",
    "def parseline(line):\n",
    "    fields = line.split(',')\n",
    "    Reason = fields[0]\n",
    "    return (Reason, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41ac7c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use all the data in the input file\n",
    "#  NB if your breathtest file has a header line it may fail here. Copy the file and remove the header.\n",
    "#\n",
    "def parseline2(line):\n",
    "    fields = line.split(',')\n",
    "    Reason = fields[0]\n",
    "    Month = fields[1]\n",
    "    Year = fields[2]\n",
    "    WeekType = fields[3]\n",
    "    TimeBand = fields[4]\n",
    "    BreathAlcoholLevel = int(fields[5])\n",
    "    AgeBand = fields[6]\n",
    "    if fields[7]=='Female':\n",
    "        Gender = 2\n",
    "    else:\n",
    "        Gender = 1\n",
    "    return (Reason,Month,Year,WeekType,TimeBand,BreathAlcoholLevel,AgeBand,Gender)\n",
    "\n",
    "header = lines.first() #extract header\n",
    "justdata = lines.filter(lambda row: row != header)\n",
    "#Apply the parseline function to the lines -- evaluation is lazy\n",
    "allreasons = justdata.map(parseline2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a62712a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497790"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count total lines in the file -- now must call evaluated so you get a noticeable delay\n",
    "allreasons.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66829624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Moving Traffic Violation',\n",
       "  'Jan',\n",
       "  '2013',\n",
       "  'Weekday',\n",
       "  '12am-4am',\n",
       "  80,\n",
       "  '30-39',\n",
       "  1),\n",
       " ('Road Traffic Collision',\n",
       "  'Jan',\n",
       "  '2013',\n",
       "  'Weekday',\n",
       "  '12am-4am',\n",
       "  0,\n",
       "  'Other',\n",
       "  1),\n",
       " ('Road Traffic Collision',\n",
       "  'Jan',\n",
       "  '2013',\n",
       "  'Weekday',\n",
       "  '12am-4am',\n",
       "  96,\n",
       "  'Other',\n",
       "  1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allreasons.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b5d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Moving Traffic Violation': 179064,\n",
       "             'Road Traffic Collision': 168526,\n",
       "             'Suspicion of Alcohol': 94685,\n",
       "             'Other': 55372,\n",
       "             'Unknown': 143})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RDD version\n",
    "#Count the different reason types -- just output the value. This should be formatted using print, printf etc\n",
    "allreasons.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "809debe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(allreasons, header.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc118b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Reason: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- WeekType: string (nullable = true)\n",
      " |-- TimeBand: string (nullable = true)\n",
      " |-- BreathAlcoholLevel(microg 100ml): long (nullable = true)\n",
      " |-- AgeBand: string (nullable = true)\n",
      " |-- Gender: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6de1bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "497790"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a775d2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/pyspark/sql/dataframe.py:138: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df.registerTempTable(\"BreathData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4210632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Reason='Suspicion of Alcohol')\n",
      "Row(Reason='Road Traffic Collision')\n",
      "Row(Reason='Unknown')\n",
      "Row(Reason='Other')\n",
      "Row(Reason='Moving Traffic Violation')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Basic SQL Operation (RDDs are immutable so consider queries carefully). Note that we must collect() results from our query \n",
    "# or its execution is delayed.\n",
    "distinct_reasons = spark.sql(\"select distinct Reason from BreathData\")\n",
    "for b in distinct_reasons.collect(): \n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ce34440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumnRenamed('BreathAlcoholLevel(microg 100ml)', 'AlcoholLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efeaa5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Prepare 'male' and 'female' sub-dataframes \n",
    "# Your code set Gender=1 for Male, Gender=2 for Female\n",
    "mAlltests = df2.filter(col(\"Gender\") == 1)\n",
    "fAlltests = df2.filter(col(\"Gender\") == 2)\n",
    "\n",
    "# Prepare positive (BreathAlcoholLevel > 35) subsets [cite: 25]\n",
    "mPostests = mAlltests.filter(col(\"AlcoholLevel\") > 35)\n",
    "fPostests = fAlltests.filter(col(\"AlcoholLevel\") > 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b7a2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tests for Males: 43029\n",
      "Positive tests for Females: 8459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Count the positive tests for each gender\n",
    "male_positive_count = mPostests.count()\n",
    "female_positive_count = fPostests.count()\n",
    "\n",
    "print(f\"Positive tests for Males: {male_positive_count}\")\n",
    "print(f\"Positive tests for Females: {female_positive_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1355424d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of Failed Breath Tests by Month:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>total_tests</th>\n",
       "      <th>positive_tests</th>\n",
       "      <th>fail_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aug</td>\n",
       "      <td>29303</td>\n",
       "      <td>4813</td>\n",
       "      <td>0.164249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sep</td>\n",
       "      <td>25480</td>\n",
       "      <td>3951</td>\n",
       "      <td>0.155063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>May</td>\n",
       "      <td>32617</td>\n",
       "      <td>4909</td>\n",
       "      <td>0.150504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oct</td>\n",
       "      <td>27025</td>\n",
       "      <td>4045</td>\n",
       "      <td>0.149676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr</td>\n",
       "      <td>29663</td>\n",
       "      <td>4126</td>\n",
       "      <td>0.139096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mar</td>\n",
       "      <td>31351</td>\n",
       "      <td>4357</td>\n",
       "      <td>0.138975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nov</td>\n",
       "      <td>31469</td>\n",
       "      <td>4191</td>\n",
       "      <td>0.133179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jul</td>\n",
       "      <td>34535</td>\n",
       "      <td>4575</td>\n",
       "      <td>0.132474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Feb</td>\n",
       "      <td>24982</td>\n",
       "      <td>3192</td>\n",
       "      <td>0.127772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jan</td>\n",
       "      <td>26045</td>\n",
       "      <td>3033</td>\n",
       "      <td>0.116452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jun</td>\n",
       "      <td>83406</td>\n",
       "      <td>5170</td>\n",
       "      <td>0.061986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dec</td>\n",
       "      <td>121914</td>\n",
       "      <td>5126</td>\n",
       "      <td>0.042046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  total_tests  positive_tests  fail_proportion\n",
       "0    Aug        29303            4813         0.164249\n",
       "1    Sep        25480            3951         0.155063\n",
       "2    May        32617            4909         0.150504\n",
       "3    Oct        27025            4045         0.149676\n",
       "4    Apr        29663            4126         0.139096\n",
       "5    Mar        31351            4357         0.138975\n",
       "6    Nov        31469            4191         0.133179\n",
       "7    Jul        34535            4575         0.132474\n",
       "8    Feb        24982            3192         0.127772\n",
       "9    Jan        26045            3033         0.116452\n",
       "10   Jun        83406            5170         0.061986\n",
       "11   Dec       121914            5126         0.042046"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate total tests per month from the main DataFrame\n",
    "all_tests_monthly = df2.groupBy(\"Month\").count().withColumnRenamed(\"count\", \"total_tests\")\n",
    "\n",
    "# Calculate positive tests per month\n",
    "positive_tests = df2.filter(col(\"AlcoholLevel\") > 35)\n",
    "positive_tests_monthly = positive_tests.groupBy(\"Month\").count().withColumnRenamed(\"count\", \"positive_tests\")\n",
    "\n",
    "# Join the two DataFrames \n",
    "proportions_df = all_tests_monthly.join(positive_tests_monthly, \"Month\")\n",
    "\n",
    "# Add a new column to calculate the proportion\n",
    "proportions_final_df = proportions_df.withColumn(\n",
    "    \"fail_proportion\",\n",
    "    (col(\"positive_tests\") / col(\"total_tests\"))\n",
    ").orderBy(col(\"fail_proportion\").desc())\n",
    "\n",
    "print(\"Proportion of Failed Breath Tests by Month:\")\n",
    "# Convert to Pandas for a nicely formatted display, as suggested by the lab\n",
    "proportions_final_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b06f021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Reason,StringType,true),StructField(Month,StringType,true),StructField(Year,StringType,true),StructField(WeekType,StringType,true),StructField(TimeBand,StringType,true),StructField(AlcoholLevel,LongType,true),StructField(AgeBand,StringType,true),StructField(Gender,LongType,true)))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "608745fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to Pandas DataFrame...\n",
      "CPU times: user 3.9 ms, sys: 896 Âµs, total: 4.8 ms\n",
      "Wall time: 67.9 ms\n",
      "\n",
      "Pandas DataFrame Summary:\n",
      "         total_tests  positive_tests  fail_proportion\n",
      "count      12.000000       12.000000        12.000000\n",
      "mean    41482.500000     4290.666667         0.125956\n",
      "std     29879.015721      688.409938         0.037102\n",
      "min     24982.000000     3033.000000         0.042046\n",
      "25%     26780.000000     4021.500000         0.124942\n",
      "50%     30507.000000     4274.000000         0.136077\n",
      "75%     33096.500000     4837.000000         0.149883\n",
      "max    121914.000000     5170.000000         0.164249\n"
     ]
    }
   ],
   "source": [
    "# Convert your Spark DataFrame to a Pandas DataFrame\n",
    "print(\"Converting to Pandas DataFrame...\")\n",
    "# The %time command is used to measure how long the conversion takes\n",
    "%time pandas_df = proportions_final_df.toPandas()\n",
    "# Run a basic summary command\n",
    "print(\"\\nPandas DataFrame Summary:\")\n",
    "print(pandas_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c670661f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Moving Traffic Violation', 179064),\n",
       " ('Road Traffic Collision', 168526),\n",
       " ('Suspicion of Alcohol', 94685),\n",
       " ('Other', 55372),\n",
       " ('Unknown', 143)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by 'Reason' and count occurrences\n",
    "reason_counts = allreasons.map(lambda x: (x[0], 1)).reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# Sort by count in descending order\n",
    "sorted_reason_counts = reason_counts.sortBy(lambda x: -x[1])\n",
    "\n",
    "# Display the top 5 most common reasons\n",
    "sorted_reason_counts.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73b3a5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Profile of a FAILED Test ---\n",
      "Most Common Time of Day for a FAILED Test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|TimeBand|count|\n",
      "+--------+-----+\n",
      "|12am-4am|17655|\n",
      "|8pm-12pm|12878|\n",
      "|4pm-8pm |6729 |\n",
      "|4am-8am |5964 |\n",
      "|8am-12pm|4292 |\n",
      "+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "# For a FAILED test, what is the most common time of day and age?\n",
    "print(\"\\n--- Profile of a FAILED Test ---\")\n",
    "print(\"Most Common Time of Day for a FAILED Test:\")\n",
    "positive_tests.groupBy(\"TimeBand\").count().orderBy(desc(\"count\")).show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4496a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Common Age Group for a FAILED Test:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|AgeBand|count|\n",
      "+-------+-----+\n",
      "|30-39  |10957|\n",
      "|40-49  |8442 |\n",
      "|20-24  |8000 |\n",
      "|25-29  |7224 |\n",
      "|Other  |7149 |\n",
      "+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(\"Most Common Age Group for a FAILED Test:\")\n",
    "positive_tests.groupBy(\"AgeBand\").count().orderBy(desc(\"count\")).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e0dcb",
   "metadata": {},
   "source": [
    "#frpm to the bottom continues the normal exercise for wek 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f38acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.select('*').filter(df2.AlcoholLevel > 35).orderBy(df2.AlcoholLevel.desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7ab2e34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+--------+--------+------------+-------+------+\n",
      "|              Reason|Month|Year|WeekType|TimeBand|AlcoholLevel|AgeBand|Gender|\n",
      "+--------------------+-----+----+--------+--------+------------+-------+------+\n",
      "|Moving Traffic Vi...|  Mar|2013| Weekday| 4am-8am|         745|  40-49|     1|\n",
      "|Road Traffic Coll...|  May|2013| Weekend| 4am-8am|         676|  16-19|     1|\n",
      "|Suspicion of Alcohol|  Jun|2013| Weekday|12am-4am|         667|  20-24|     1|\n",
      "|Road Traffic Coll...|  Nov|2013| Weekday|12am-4am|         565|  70-98|     1|\n",
      "|Suspicion of Alcohol|  Apr|2013| Weekend| 4am-8am|         562|  20-24|     1|\n",
      "|Road Traffic Coll...|  Oct|2013| Weekday|8am-12pm|         538|  25-29|     1|\n",
      "|Road Traffic Coll...|  Nov|2013| Weekend|12am-4am|         531|  Other|     1|\n",
      "|Suspicion of Alcohol|  Apr|2013| Weekday|12am-4am|         527|  30-39|     2|\n",
      "|Suspicion of Alcohol|  Mar|2013| Weekday|8pm-12pm|         518|  50-59|     1|\n",
      "|Suspicion of Alcohol|  Apr|2013| Weekday|12am-4am|         517|  30-39|     2|\n",
      "+--------------------+-----+----+--------+--------+------------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f27ac945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "myschema2 = StructType(\n",
    "    [StructField(\"Reason\",StringType(),True),\n",
    "     StructField(\"Month\",StringType(),True),\n",
    "     StructField(\"Year\",IntegerType(),True),\n",
    "     StructField(\"WeekType\",StringType(),True),\n",
    "     StructField(\"TimeBand\",StringType(),True),\n",
    "     StructField(\"AlcoholLevel\",IntegerType(),True),\n",
    "     StructField(\"AgeBand\",StringType(),True),\n",
    "     StructField(\"Gender\",StringType(),True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9862df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = spark.read.load(\"DigitalBreathTestData2013.csv\",\n",
    "                      format=\"csv\", sep=\",\", schema=myschema2, \n",
    "                      header=\"true\")\\\n",
    "                    .withColumnRenamed('BreathAlcoholLevel(microg 100ml)', 'AlcoholLevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbc73b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+--------+--------+------------+-------+------+\n",
      "|              Reason|Month|Year|WeekType|TimeBand|AlcoholLevel|AgeBand|Gender|\n",
      "+--------------------+-----+----+--------+--------+------------+-------+------+\n",
      "|Moving Traffic Vi...|  Jan|2013| Weekday|12am-4am|          80|  30-39|  Male|\n",
      "|Road Traffic Coll...|  Jan|2013| Weekday|12am-4am|           0|  Other|  Male|\n",
      "|Road Traffic Coll...|  Jan|2013| Weekday|12am-4am|          96|  Other|  Male|\n",
      "|Moving Traffic Vi...|  Jan|2013| Weekday|12am-4am|           0|  40-49|Female|\n",
      "|Suspicion of Alcohol|  Jan|2013| Weekday|12am-4am|           0|  40-49|  Male|\n",
      "|Road Traffic Coll...|  Jan|2013| Weekday|8am-12pm|          45|  Other|  Male|\n",
      "|Moving Traffic Vi...|  Jan|2013| Weekday|12am-4am|          60|  30-39|  Male|\n",
      "|Moving Traffic Vi...|  Jan|2013| Weekday|12am-4am|           0|  16-19|  Male|\n",
      "|Moving Traffic Vi...|  Jan|2013| Weekday|12am-4am|           0|  16-19|  Male|\n",
      "|Moving Traffic Vi...|  Jan|2013| Weekday|8am-12pm|           0|  50-59|  Male|\n",
      "+--------------------+-----+----+--------+--------+------------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/02 11:11:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: Reason, Month, Year, WeekType, TimeBand, BreathAlcoholLevel(microg 100ml), AgeBand, Gender\n",
      " Schema: Reason, Month, Year, WeekType, TimeBand, AlcoholLevel, AgeBand, Gender\n",
      "Expected: AlcoholLevel but found: BreathAlcoholLevel(microg 100ml)\n",
      "CSV file: file:///home/notebookuser/working/data/DigitalBreathTestData2013.csv\n"
     ]
    }
   ],
   "source": [
    "df4.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7e55575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(Reason,StringType,true),StructField(Month,StringType,true),StructField(Year,IntegerType,true),StructField(WeekType,StringType,true),StructField(TimeBand,StringType,true),StructField(AlcoholLevel,IntegerType,true),StructField(AgeBand,StringType,true),StructField(Gender,StringType,true)))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
